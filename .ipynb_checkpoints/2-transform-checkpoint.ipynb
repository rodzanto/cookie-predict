{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running batch predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, we can run predictions with it in two ways:\n",
    "* Running batch transformations with a dataset stored in S3\n",
    "* Running real-time inferences through APIs to a SageMaker Endpoint\n",
    "\n",
    "For this example we will follow the batch transformation method, using the inference data stored in S3...\n",
    "\n",
    "### **Inference with SageMaker batch transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of your training data in Amazon S3\n",
    "# Change this for your own bucket name:\n",
    "bucket = 'rodzanto2020ml'\n",
    "# Change this for the location of teh data to run inference on:\n",
    "prefix = 'mediaset/final'\n",
    "inference_files = 'infer'\n",
    "# Change this for the name of your AutoML job:\n",
    "auto_ml_job_name = 'automl-ms-shuf-sdk-24-21-26-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# This is the client we will use to interact with SageMaker AutoPilot\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "#print(best_candidate)\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\"FinalAutoMLJobObjectiveMetricName: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "print(\"FinalAutoMLJobObjectiveMetricValue: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "model_name = best_candidate_name + timestamp_suffix + \"-model\"\n",
    "model = sm.create_model(Containers=best_candidate['InferenceContainers'],\n",
    "                            ModelName=model_name,\n",
    "                            ExecutionRoleArn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output = 's3://{}/{}/infer-results/'.format(bucket, prefix);\n",
    "\n",
    "transformer = sagemaker.transformer.Transformer(model_name=model_name,\n",
    "                         instance_count=1,\n",
    "                         instance_type='ml.m5.xlarge',\n",
    "                         output_path=transform_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_transform = 's3://{}/{}/{}'.format(bucket, prefix, inference_files)\n",
    "\n",
    "transformer.transform(data=input_data_transform, split_type='Line', content_type='text/csv', wait=False)\n",
    "print(\"Starting transform job {}\".format(transformer._current_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Batch Transform JobStatus')\n",
    "print('------------------------------')\n",
    "\n",
    "describe_response = sm.describe_transform_job(TransformJobName=transformer._current_job_name)\n",
    "print (strftime('%d-%H-%M-%S', gmtime()) + \" - \" + describe_response['TransformJobStatus'])\n",
    "job_run_status = describe_response['TransformJobStatus']\n",
    "    \n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_transform_job(TransformJobName=transformer._current_job_name)\n",
    "    job_run_status = describe_response['TransformJobStatus']\n",
    "    print(strftime('%d-%H-%M-%S', gmtime()) + \" - \" + describe_response['TransformJobStatus'])\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
